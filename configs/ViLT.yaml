model_name: 'ViLT'
seed: 0
checkpoint: 'checkpoints/vilt_200k_mlm_itm.ckpt' # Download from the original repository
train_file: [
              'data/multimodal_train_pairs.json'
            ]
val_file: [
  'data/multimodal_val_queries.json'
]
test_file: [
  'data/multimodal_test_queries.json'
]
document: [
  'data/multimodal_val_documents.json'
  # 'data/multimodal_documents.json'
]
image_root: '/data/chengping'
bert_config: 'configs/config_bert.json'
loss_names: {"itm": 0,
              "mlm": 0,
              "mpp": 0,
              "vqa": 0,
              "nlvr2": 0,
              "irtr": 0,}
temp: 0.07
queue_size: 9600
warm_up: True
optimizer: {opt: adamW, lr: 5e-6, weight_decay: 0.02}
schedular: {sched: cosine, lr: 5e-6, epochs: 200, min_lr: 1e-7, decay_rate: 1, warmup_lr: 5e-6, warmup_epochs: 1, cooldown_epochs: 0}
gradient_clip_value: 0.5


# Image setting
train_transform_keys: ["pixelbert"]
val_transform_keys: ["pixelbert"]
image_res: 384
max_image_len: -1
patch_size: 32
draw_false_image: 1
image_only: False

# Text Setting
vqav2_label_size: 3129
query_length: 40
text_length: 128
max_text_len: 128
tokenizer: "bert-base-uncased"
text_encoder: "bert-base-uncased"
vocab_size: 30522
whole_word_masking: False
mlm_prob: 0.15
draw_false_text: 0


# Transformer Setting
vit: "vit_base_patch32_384"
hidden_size: 768
embed_dim: 768
num_heads: 12
num_layers: 12
mlp_ratio: 4
drop_rate: 0.1

# Optimizer Setting
optim_type: "adamw"
learning_rate: 5e-5
weight_decay: 0.01
decay_power: 1
max_epoch: 100
max_steps: 25000
warmup_steps: 2500
end_lr: 0
lr_mult: 1  # multiply lr for downstream heads

# Downstream Setting
get_recall_metric: False

# PL Trainer Setting
resume_from: None
fast_dev_run: False
val_check_interval: 1.0
test_only: False

# below params varies with the environment
data_root: ""
log_dir: "result"
per_gpu_batchsize: 0  # you should define this manually with per_gpu_batch_size=#
num_gpus: 1
num_nodes: 1
load_path: ""
num_workers: 8
precision: 16